{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "**Step 1**: Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic-kernel==0.3.1.dev0\n",
      "  Downloading semantic_kernel-0.3.1.dev0-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 0.0/95.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 95.6/95.6 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting python-dotenv==1.0.0\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting aiofiles<24.0.0,>=23.1.0\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting openai<0.28.0,>=0.27.0\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 0.0/73.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 73.6/73.6 kB ? eta 0:00:00\n",
      "Collecting numpy<2.0.0,>=1.24.2\n",
      "  Downloading numpy-1.25.1-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "     ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/15.0 MB 17.1 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 2.2/15.0 MB 23.2 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 3.3/15.0 MB 23.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.6/15.0 MB 24.8 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 6.0/15.0 MB 25.7 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 7.3/15.0 MB 25.9 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 8.0/15.0 MB 25.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.5/15.0 MB 25.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 10.9/15.0 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 11.9/15.0 MB 26.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 13.4/15.0 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 14.2/15.0 MB 26.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.0/15.0 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.0/15.0 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.0/15.0 MB 22.6 MB/s eta 0:00:00\n",
      "Collecting requests>=2.20\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-win_amd64.whl (323 kB)\n",
      "     ---------------------------------------- 0.0/323.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 323.1/323.1 kB ? eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "     ---------------------------------------- 0.0/158.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 158.3/158.3 kB ? eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "     ---------------------------------------- 0.0/123.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 123.9/123.9 kB ? eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.9/96.9 kB ? eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jinle\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (0.4.6)\n",
      "Installing collected packages: urllib3, tqdm, python-dotenv, numpy, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, aiofiles, yarl, requests, aiosignal, aiohttp, openai, semantic-kernel\n",
      "Successfully installed aiofiles-23.1.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.2.0 frozenlist-1.4.0 idna-3.4 multidict-6.0.4 numpy-1.25.1 openai-0.27.8 python-dotenv-1.0.0 requests-2.31.0 semantic-kernel-0.3.1.dev0 tqdm-4.65.0 urllib3-2.0.4 yarl-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\jinle\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\jinle\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\jinle\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\jinle\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\jinle\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install semantic-kernel==0.3.1.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: using OpenAI\n",
    "\n",
    "**Step 2**: Add your [Open AI Key](https://openai.com/api/) key to a `.env` file in the same folder (org Id only if you have multiple orgs):\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "```\n",
    "\n",
    "and add OpenAI Text Completion to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextCompletion\n",
    "\n",
    "api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "\n",
    "kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: using Azure OpenAI\n",
    "\n",
    "**Step 2**: Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to a `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"...\"\n",
    "```\n",
    "\n",
    "and add Azure OpenAI Text Completion to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x1aaf4d31030>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion\n",
    "\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "\n",
    "kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a Semantic Function\n",
    "\n",
    "**Step 3**: Load a Skill and run a semantic function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "\n",
      "print(\"Why did the T-Rex go to the dentist?\")\n",
      "print(\"To get his teeth in the present tense!\")<|im_sep|>\n"
     ]
    }
   ],
   "source": [
    "skill = kernel.import_semantic_skill_from_directory(\"../../skills\", \"FunSkill\")\n",
    "joke_function = skill[\"Joke\"]\n",
    "\n",
    "print(joke_function(\"write a funny joke about time travel to dinosaur age\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
